{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/minigpt_env/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/minigpt_env/lib/libcudart.so.11.0'), PosixPath('/home/minigpt_env/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaConfig, LlamaTokenizer,LlamaForCausalLM, LlamaTokenizer,TextDataset,DataCollatorForLanguageModeling\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig ,LoraConfig,TaskType\n",
    "from transformers import TrainingArguments, Trainer,GenerationConfig,LineByLineTextDataset\n",
    "from datasets import Dataset , load_dataset\n",
    "import torch\n",
    "import accelerate\n",
    "from transformers.generation.utils import GreedySearchDecoderOnlyOutput\n",
    "import textwrap\n",
    "#import bitsandbytes\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import re\n",
    "from vicuna_setup import vicuna_inference\n",
    "from vicuna_pubmedqa_eval import model_pubmed_evaluator\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import Counter\n",
    "from evaluation import pub_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/vicuna-weights-7B\"\n",
    "model_path=\"/home/vicuna-weights-7B\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = LlamaForCausalLM.from_pretrained(path)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2\n",
    "\n",
    "pubmed_config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=3,\n",
    "        min_length=1,\n",
    "        max_time=3,\n",
    "        max_new_tokens=3, # 3\n",
    "        forced_bos_token_id=[tokenizer.encode(\"yes\")[1], tokenizer.encode(\"no\")[1], tokenizer.encode(\"maybe\")[1]],\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_dict=model_pubmed_evaluator(model=model,tokenizer=tokenizer,config=pubmed_config,id_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/medical-llama/pubmed-pred/base.json\", \"w\") as json_file:\n",
    "    json.dump(ans_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_scores(\"/home/medical-llama/pubmed-pred/base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,f1_macro=[],[]\n",
    "for i in range(5):\n",
    "    ans_dict=model_pubmed_evaluator(model=model,tokenizer=tokenizer,config=pubmed_config,id_=i)\n",
    "    with open(\"/home/medical-llama/pubmed-pred/base.json\", \"w\") as json_file:\n",
    "        json.dump(ans_dict, json_file)\n",
    "    accuracy,f1=pub_scores(\"/home/medical-llama/pubmed-pred/base.json\")\n",
    "    acc.append(accuracy)\n",
    "    f1_macro.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \",np.mean(acc))\n",
    "print(\"F1 Macro: \",np.mean(f1_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/home/medical-llama/Pubmedqa/pubmedqa/data/pubmedqa_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=128,\n",
    "        min_length=1,\n",
    "        max_time=10,\n",
    "        max_new_tokens=128,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is generally not recommended to mix paracetamol with alcohol as it\n",
      "can cause stomach problems and potentially lead to liver damage. If\n",
      "you have any concerns or questions about taking paracetamol, it's best\n",
      "to consult with a healthcare professional. \n"
     ]
    }
   ],
   "source": [
    "print(vicuna_inference(\"can i take paracetamol & drink alcohol ?\",model=model,tokenizer=tokenizer,config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_template(Question, Context,id=0):\n",
    "\n",
    "    prompt_template=f\"\"\"\n",
    "    \n",
    "    your task is to answering research questions relating to medical domain using yes/no/maybe responses. Answer as yes if the context supports the question , answer as no if the context does not support the question , answer as maybe if the context is not clear enough to answer the question.      \n",
    "\n",
    "    ###\n",
    "            \n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are dogs trainable?\n",
    "\n",
    "    Answer: yes\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\n",
    "\n",
    "    Answer: maybe\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are Dogs highly introverted & reserved ?\n",
    "\n",
    "    Answer: no \n",
    "\n",
    "    ###\n",
    "\n",
    "    Context:\n",
    "    {Context}\n",
    "\n",
    "    Question:\n",
    "    {Question}\n",
    "\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
