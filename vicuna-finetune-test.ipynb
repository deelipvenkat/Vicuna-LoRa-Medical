{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/minigpt_env/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/minigpt_env/lib/libcudart.so'), PosixPath('/home/minigpt_env/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaConfig, LlamaTokenizer,LlamaForCausalLM, LlamaTokenizer,TextDataset,DataCollatorForLanguageModeling\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig ,LoraConfig,TaskType\n",
    "from transformers import TrainingArguments, Trainer,GenerationConfig,LineByLineTextDataset\n",
    "from datasets import Dataset , load_dataset\n",
    "import torch\n",
    "import textwrap\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import re\n",
    "%aimport vicuna_setup\n",
    "from vicuna_pubmedqa_eval import model_pubmed_evaluator\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import Counter\n",
    "from evaluation import pub_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/vicuna-weights-7B\"\n",
    "peft_path=\"/home/medical-llama/vicuna-lora-7B\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path,clean_up_tokenization_spaces=True,padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"/home/medical-llama/vicuna-lora-7B/adapter_config.json\", 'r') as json_file:\n",
    "#    lora_config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = LlamaForCausalLM.from_pretrained(model_path)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peft_config = PeftConfig.from_pretrained(peft_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        peft_path,\n",
    "        torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=5,\n",
    "        min_length=1,\n",
    "        max_time=3,\n",
    "        max_new_tokens=10, # 3\n",
    "        #forced_bos_token_id=[tokenizer.encode(\"yes\")[1], tokenizer.encode(\"no\")[1], tokenizer.encode(\"maybe\")[1]],\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/medical-llama/Pubmedqa/pubmedqa/data/pubmedqa_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_template(Question, Context):\n",
    "        \n",
    "        prompt_template=f\"\"\"\n",
    "    Respond with \"yes\",\"no\",\"maybe\" using the context & the question provided.    \n",
    "     \n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are dogs trainable?\n",
    "\n",
    "    Answer: yes\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\n",
    "\n",
    "    Answer: maybe\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are Dogs highly introverted & reserved ?\n",
    "\n",
    "    Answer: no \n",
    "\n",
    "\n",
    "    Context:\n",
    "    {Context}\n",
    "\n",
    "    Question:\n",
    "    {Question}\n",
    "\n",
    "    Answer: \n",
    "    \n",
    "    \"\"\"\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_template(Question, Context):\n",
    "        \n",
    "        prompt_template=f\"\"\"\n",
    "\n",
    "    your task is to answering research questions relating to medical domain using yes/no/maybe responses. Answer as yes if the context supports the question , answer as no if the context does not support the question , answer as maybe if the context is not clear enough to answer the question.      \n",
    "\n",
    "    ###\n",
    "            \n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are dogs trainable?\n",
    "\n",
    "    Answer: yes\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\n",
    "\n",
    "    Answer: maybe\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are Dogs highly introverted & reserved ?\n",
    "\n",
    "    Answer: no \n",
    "\n",
    "    ###\n",
    "\n",
    "    Context:\n",
    "    {Context}\n",
    "\n",
    "    Question:\n",
    "    {Question}\n",
    "\n",
    "    Answer: \n",
    "    \n",
    "    \"\"\"\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vicuna_setup.vicuna_inference(pubmed_template(Question=str(df['Question'][5]),Context=str(df['Context'][5])),model=model,tokenizer=tokenizer,config=pubmed_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_30693/3327623571.py\", line 1, in <module>\n",
      "    tokenizer.decode([-100])\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\", line 3496, in decode\n",
      "    return self._decode(\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/transformers/tokenization_utils.py\", line 931, in _decode\n",
      "    filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/transformers/tokenization_utils.py\", line 912, in convert_ids_to_tokens\n",
      "    tokens.append(self._convert_id_to_token(index))\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/transformers/models/llama/tokenization_llama.py\", line 129, in _convert_id_to_token\n",
      "    token = self.sp_model.IdToPiece(index)\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/sentencepiece/__init__.py\", line 1045, in _batched_func\n",
      "    return _func(self, arg)\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/sentencepiece/__init__.py\", line 1038, in _func\n",
      "    raise IndexError('piece id is out of range.')\n",
      "IndexError: piece id is out of range.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1082, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/home/minigpt_env/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pubmed_template(Question=df['Question'][0],Context=df['Context'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=128,\n",
    "        min_length=1,\n",
    "        max_time=10,\n",
    "        max_new_tokens=128,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vicuna_inference(\"can i take paracetamol & drink alcohol ?\",model=model,tokenizer=tokenizer,config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict={}\n",
    "for i in range(int(df.shape[0]/10)):\n",
    "    pmid=str(df['ID'][i])\n",
    "    ans=vicuna_inference(pubmed_template(Question=df['Question'][i],Context=df['Context'][i]),model=model,tokenizer=tokenizer,config=pubmed_config)\n",
    "    ans_dict[pmid]=ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict=model_pubmed_evaluator(model=model,tokenizer=tokenizer,config=pubmed_config,id_=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n \\n### Instruction:\\n\\n    Respond with \"yes\",\"no\",\"maybe\" using the context & the question provided.    \\n     \\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are dogs trainable?\\n\\n    Answer: yes\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\\n\\n    Answer: maybe\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are Dogs highly introverted & reserved ?\\n\\n    Answer: no \\n\\n\\n    Context:\\n    A case of spinal subdural hematoma (SSDH) following subarachnoid hemorrhage (SAH) because of a ruptured internal carotid aneurysm is described. Such a case has never been reported. A 52-year-old woman underwent a craniotomy for a ruptured internal carotid aneurysm. A computed tomography scan showed that SAH existed predominantly in the posterior fossa and subdural hematoma beneath the cerebellar tentorium. Intrathecal administration of urokinase, IV administration of fasudil hydrochloride, and continuous cerebrospinal fluid (CSF) evacuation via cisternal drainage were performed as prophylactic treatments for vasospasm. On the sixth postoperative day, the patient complained of severe lower back and buttock pain. Magnetic resonance imaging showed a subdural hematoma in the lumbosacral region. Although the mass effect was extensive, the patient showed no neurologic symptoms other than the sciatica. She was treated conservatively. The hematoma dissolved gradually and had diminished completely 15 weeks later. Her pain gradually subsided, and she was discharged 7 weeks later without any neurologic deficit.\\n\\n    Question:\\n    Spinal subdural hematoma: a sequela of a ruptured intracranial aneurysm?\\n\\n    Answer: \\n    \\n    \\n \\n### Response:\\n\\n  \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs of model \n",
    "tokenizer.decode([ 1, 29871,    13, 21140,   340,   338,   385, 15278,   393, 16612,\n",
    "           263,  3414, 29889, 14350,   263,  2933,   393,  7128,  2486,  1614,\n",
    "          2167,   278,  2009, 29889,    13, 29871,    13,  2277, 29937,  2799,\n",
    "          4080, 29901,    13,    13,  1678,  2538,  2818,   411,   376,  3582,\n",
    "          3284,  1217,  3284, 26026, 29908,   773,   278,  3030,   669,   278,\n",
    "          1139,  4944, 29889,   268,    13,   418,    13,  1678, 15228, 29901,\n",
    "         10550, 21677, 26361,   756,  1063, 11395,   284,   297,  3061, 19985,\n",
    "          1749,  8004,   310,  5164, 16021,  4235, 29889,   360, 12099,   526,\n",
    "         10712,  7945,   519,   322,  5374,   519, 15006, 29889,    13,    13,\n",
    "          1678,   894, 29901,  4683, 26361,  7945,   519, 29973,    13,    13,\n",
    "          1678,   673, 29901,  4874,    13,    13,  1678, 15228, 29901, 10550,\n",
    "         21677, 26361,   756,  1063, 11395,   284,   297,  3061, 19985,  1749,\n",
    "          8004,   310,  5164, 16021,  4235, 29889,   360, 12099,   526, 10712,\n",
    "          7945,   519,   322,  5374,   519, 15006, 29889,    13,    13,  1678,\n",
    "           894, 29901,  1815, 26361,   367, 16370,   304,  6459,   322,  6655,\n",
    "         15724,   304,   278, 10122,   310,  2702,   599, 15064,   575, 29973,\n",
    "            13,    13,  1678,   673, 29901,  5505,    13,    13,  1678, 15228,\n",
    "         29901, 10550, 21677, 26361,   756,  1063, 11395,   284,   297,  3061,\n",
    "         19985,  1749,  8004,   310,  5164, 16021,  4235, 29889,   360, 12099,\n",
    "           526, 10712,  7945,   519,   322,  5374,   519, 15006, 29889,    13,\n",
    "            13,  1678,   894, 29901,  4683,   360, 12099, 10712, 22909,  1765,\n",
    "           287,   669, 21676,  1577,    13,    13,  1678,   673, 29901,   694,\n",
    "         29871,    13,    13,    13,  1678, 15228, 29901,    13,  1678,   319,\n",
    "          1206,   310,   805,   979,  1014, 29881,  3631,   298,  4579,  4125,\n",
    "           313,  1799, 29928, 29950, 29897,  1494,  1014,   279,   496,  1217,\n",
    "           333,  9736,   272, 19046,   482,   313,  8132, 29950, 29897,  1363,\n",
    "           310,   263,  5796,   415,  2955,  7463,  1559,   327,   333,   385,\n",
    "          5411,   952, 29885,   338,  5439, 29889, 10506,   263,  1206,   756,\n",
    "          2360,  1063,  8967, 29889,   319, 29871, 29945, 29906, 29899,  6360,\n",
    "         29899,  1025,  6114,  1090, 29893,   296,   263,   274,   661, 24414,\n",
    "         16103,   363,   263,  5796,   415,  2955,  7463,  1559,   327,   333,\n",
    "           385,  5411,   952, 29885, 29889,   319, 15712,  6454,  5275, 12812,\n",
    "         10018,   393, 16698, 29950, 22856,   758, 24130, 10835,   297,   278,\n",
    "         13446,   285, 20634,   322,  1014, 29881,  3631,   298,  4579,  4125,\n",
    "         19540,   278,   274,   406, 12562,   279, 12033,   272,  1974, 29889,\n",
    "           512, 26614,   354,  1052, 17517,   310,   318,   307,  9089,   559,\n",
    "         29892,  6599, 17517,   310, 25995,   566,   309, 17546,   305,  5095,\n",
    "           680, 29892,   322,  9126,   274,   406,  6729,  1028,   979, 22576,\n",
    "           313,  9295, 29943, 29897,  3415, 22061,   362,  3025,   274,   275,\n",
    "          1890,   270,  6038,   482,   892,  8560,   408,   410, 11461,   433,\n",
    "         20009,  7539,  1860,   363, 19723,  4705, 11625, 29889,  1551,   278,\n",
    "         25963,  1400,  3372,  1230,  2462, 29892,   278, 16500, 15313,  1312,\n",
    "           310, 22261,  5224,  1250,   322,   541,   517,   384,  6788, 29889,\n",
    "          3561,  1212,   293, 27396,   749,  6382,   292, 10018,   263,  1014,\n",
    "         29881,  3631,   298,  4579,  4125,   297,   278,   301,  3774,   359,\n",
    "           562,  1705,  5120, 29889,  8512,   278,  4158,  2779,   471, 20607,\n",
    "         29892,   278, 16500, 10018,   694,   452,  2192, 19227, 25828,  4835,\n",
    "           916,  1135,   278,  4560, 29288, 29889,  2296,   471, 14914,  8976,\n",
    "          6703, 29889,   450,   298,  4579,  4125, 23556,  1490, 22020,   322,\n",
    "           750, 22964,  3276,  6446, 29871, 29896, 29945, 11405,  2678, 29889,\n",
    "          2439,  6788, 22020, 11684,  2618, 29892,   322,  1183,   471,   766,\n",
    "         25389,   287, 29871, 29955, 11405,  2678,  1728,   738,   452,  2192,\n",
    "         19227,   822,   293,   277, 29889,    13,    13,  1678,   894, 29901,\n",
    "            13,  1678,  1706,   979,  1014, 29881,  3631,   298,  4579,  4125,\n",
    "         29901,   263,  8617,  3100,   310,   263,  5796,   415,  2955,   938,\n",
    "           945,   661,   616,   385,  5411,   952, 29885, 29973,    13,    13,\n",
    "          1678,   673, 29901, 29871,    13,   268,    13,   268,    13, 29871,\n",
    "            13,  2277, 29937, 13291, 29901,    13,    13,   259,    13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n \\n### Instruction:\\n\\n\\n    your task is to answering research questions relating to medical domain using yes/no/maybe responses. Answer as yes if the context supports the question , answer as no if the context does not support the question , answer as maybe if the context is not clear enough to answer the question.      \\n\\n    ###\\n            \\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are dogs trainable?\\n\\n    Answer: yes\\n\\n    ###\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\\n\\n    Answer: maybe\\n\\n    ###\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are Dogs highly introverted & reserved ?\\n\\n    Answer: no \\n\\n    ###\\n\\n    Context:\\n    A case of spinal subdural hematoma (SSDH) following subarachnoid hemorrhage (SAH) because of a ruptured internal carotid aneurysm is described. Such a case has never been reported. A 52-year-old woman underwent a craniotomy for a ruptured internal carotid aneurysm. A computed tomography scan showed that SAH existed predominantly in the posterior fossa and subdural hematoma beneath the cerebellar tentorium. Intrathecal administration of urokinase, IV administration of fasudil hydrochloride, and continuous cerebrospinal fluid (CSF) evacuation via cisternal drainage were performed as prophylactic treatments for vasospasm. On the sixth postoperative day, the patient complained of severe lower back and buttock pain. Magnetic resonance imaging showed a subdural hematoma in the lumbosacral region. Although the mass effect was extensive, the patient showed no neurologic symptoms other than the sciatica. She was treated conservatively. The hematoma dissolved gradually and had diminished completely 15 weeks later. Her pain gradually subsided, and she was discharged 7 weeks later without any neurologic deficit.\\n\\n    Question:\\n    Spinal subdural hematoma: a sequela of a ruptured intracranial aneurysm?\\n\\n    Answer: \\n    \\n    \\n \\n### Response:\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input tokenization\n",
    "tokenizer.decode([1, 29871,    13, 21140,   340,   338,   385, 15278,   393, 16612,\n",
    "           263,  3414, 29889, 14350,   263,  2933,   393,  7128,  2486,  1614,\n",
    "          2167,   278,  2009, 29889,    13, 29871,    13,  2277, 29937,  2799,\n",
    "          4080, 29901,    13,    13,    13,  1678,   596,  3414,   338,   304,\n",
    "         22862,  5925,  5155,  1104,  1218,   304, 16083,  5354,   773,  4874,\n",
    "         29914,  1217, 29914, 26026, 20890, 29889,   673,   408,  4874,   565,\n",
    "           278,  3030, 11286,   278,  1139,  1919,  1234,   408,   694,   565,\n",
    "           278,  3030,   947,   451,  2304,   278,  1139,  1919,  1234,   408,\n",
    "          5505,   565,   278,  3030,   338,   451,  2821,  3307,   304,  1234,\n",
    "           278,  1139, 29889,   539,    13,    13,  1678,   835,    13,   632,\n",
    "            13,  1678, 15228, 29901, 10550, 21677, 26361,   756,  1063, 11395,\n",
    "           284,   297,  3061, 19985,  1749,  8004,   310,  5164, 16021,  4235,\n",
    "         29889,   360, 12099,   526, 10712,  7945,   519,   322,  5374,   519,\n",
    "         15006, 29889,    13,    13,  1678,   894, 29901,  4683, 26361,  7945,\n",
    "           519, 29973,    13,    13,  1678,   673, 29901,  4874,    13,    13,\n",
    "          1678,   835,    13,    13,  1678, 15228, 29901, 10550, 21677, 26361,\n",
    "           756,  1063, 11395,   284,   297,  3061, 19985,  1749,  8004,   310,\n",
    "          5164, 16021,  4235, 29889,   360, 12099,   526, 10712,  7945,   519,\n",
    "           322,  5374,   519, 15006, 29889,    13,    13,  1678,   894, 29901,\n",
    "          1815, 26361,   367, 16370,   304,  6459,   322,  6655, 15724,   304,\n",
    "           278, 10122,   310,  2702,   599, 15064,   575, 29973,    13,    13,\n",
    "          1678,   673, 29901,  5505,    13,    13,  1678,   835,    13,    13,\n",
    "          1678, 15228, 29901, 10550, 21677, 26361,   756,  1063, 11395,   284,\n",
    "           297,  3061, 19985,  1749,  8004,   310,  5164, 16021,  4235, 29889,\n",
    "           360, 12099,   526, 10712,  7945,   519,   322,  5374,   519, 15006,\n",
    "         29889,    13,    13,  1678,   894, 29901,  4683,   360, 12099, 10712,\n",
    "         22909,  1765,   287,   669, 21676,  1577,    13,    13,  1678,   673,\n",
    "         29901,   694, 29871,    13,    13,  1678,   835,    13,    13,  1678,\n",
    "         15228, 29901,    13,  1678,   319,  1206,   310,   805,   979,  1014,\n",
    "         29881,  3631,   298,  4579,  4125,   313,  1799, 29928, 29950, 29897,\n",
    "          1494,  1014,   279,   496,  1217,   333,  9736,   272, 19046,   482,\n",
    "           313,  8132, 29950, 29897,  1363,   310,   263,  5796,   415,  2955,\n",
    "          7463,  1559,   327,   333,   385,  5411,   952, 29885,   338,  5439,\n",
    "         29889, 10506,   263,  1206,   756,  2360,  1063,  8967, 29889,   319,\n",
    "         29871, 29945, 29906, 29899,  6360, 29899,  1025,  6114,  1090, 29893,\n",
    "           296,   263,   274,   661, 24414, 16103,   363,   263,  5796,   415,\n",
    "          2955,  7463,  1559,   327,   333,   385,  5411,   952, 29885, 29889,\n",
    "           319, 15712,  6454,  5275, 12812, 10018,   393, 16698, 29950, 22856,\n",
    "           758, 24130, 10835,   297,   278, 13446,   285, 20634,   322,  1014,\n",
    "         29881,  3631,   298,  4579,  4125, 19540,   278,   274,   406, 12562,\n",
    "           279, 12033,   272,  1974, 29889,   512, 26614,   354,  1052, 17517,\n",
    "           310,   318,   307,  9089,   559, 29892,  6599, 17517,   310, 25995,\n",
    "           566,   309, 17546,   305,  5095,   680, 29892,   322,  9126,   274,\n",
    "           406,  6729,  1028,   979, 22576,   313,  9295, 29943, 29897,  3415,\n",
    "         22061,   362,  3025,   274,   275,  1890,   270,  6038,   482,   892,\n",
    "          8560,   408,   410, 11461,   433, 20009,  7539,  1860,   363, 19723,\n",
    "          4705, 11625, 29889,  1551,   278, 25963,  1400,  3372,  1230,  2462,\n",
    "         29892,   278, 16500, 15313,  1312,   310, 22261,  5224,  1250,   322,\n",
    "           541,   517,   384,  6788, 29889,  3561,  1212,   293, 27396,   749,\n",
    "          6382,   292, 10018,   263,  1014, 29881,  3631,   298,  4579,  4125,\n",
    "           297,   278,   301,  3774,   359,   562,  1705,  5120, 29889,  8512,\n",
    "           278,  4158,  2779,   471, 20607, 29892,   278, 16500, 10018,   694,\n",
    "           452,  2192, 19227, 25828,  4835,   916,  1135,   278,  4560, 29288,\n",
    "         29889,  2296,   471, 14914,  8976,  6703, 29889,   450,   298,  4579,\n",
    "          4125, 23556,  1490, 22020,   322,   750, 22964,  3276,  6446, 29871,\n",
    "         29896, 29945, 11405,  2678, 29889,  2439,  6788, 22020, 11684,  2618,\n",
    "         29892,   322,  1183,   471,   766, 25389,   287, 29871, 29955, 11405,\n",
    "          2678,  1728,   738,   452,  2192, 19227,   822,   293,   277, 29889,\n",
    "            13,    13,  1678,   894, 29901,    13,  1678,  1706,   979,  1014,\n",
    "         29881,  3631,   298,  4579,  4125, 29901,   263,  8617,  3100,   310,\n",
    "           263,  5796,   415,  2955,   938,   945,   661,   616,   385,  5411,\n",
    "           952, 29885, 29973,    13,    13,  1678,   673, 29901, 29871,    13,\n",
    "           268,    13,   268,    13, 29871,    13,  2277, 29937, 13291, 29901,\n",
    "            13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n \\n### Instruction:\\n\\n\\n    your task is to answering research questions relating to medical domain using yes/no/maybe responses. Answer as yes if the context supports the question , answer as no if the context does not support the question , answer as maybe if the context is not clear enough to answer the question.      \\n\\n    ###\\n            \\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are dogs trainable?\\n\\n    Answer: yes\\n\\n    ###\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\\n\\n    Answer: maybe\\n\\n    ###\\n\\n    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\\n\\n    Question: Are Dogs highly introverted & reserved ?\\n\\n    Answer: no \\n\\n    ###\\n\\n    Context:\\n    A case of spinal subdural hematoma (SSDH) following subarachnoid hemorrhage (SAH) because of a ruptured internal carotid aneurysm is described. Such a case has never been reported. A 52-year-old woman underwent a craniotomy for a ruptured internal carotid aneurysm. A computed tomography scan showed that SAH existed predominantly in the posterior fossa and subdural hematoma beneath the cerebellar tentorium. Intrathecal administration of urokinase, IV administration of fasudil hydrochloride, and continuous cerebrospinal fluid (CSF) evacuation via cisternal drainage were performed as prophylactic treatments for vasospasm. On the sixth postoperative day, the patient complained of severe lower back and buttock pain. Magnetic resonance imaging showed a subdural hematoma in the lumbosacral region. Although the mass effect was extensive, the patient showed no neurologic symptoms other than the sciatica. She was treated conservatively. The hematoma dissolved gradually and had diminished completely 15 weeks later. Her pain gradually subsided, and she was discharged 7 weeks later without any neurologic deficit.\\n\\n    Question:\\n    Spinal subdural hematoma: a sequela of a ruptured intracranial aneurysm?\\n\\n    Answer: \\n    \\n    \\n \\n### Response:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long max_tokens =output\n",
    "tokenizer.decode([    1, 29871,    13, 21140,   340,   338,   385, 15278,   393, 16612,\n",
    "           263,  3414, 29889, 14350,   263,  2933,   393,  7128,  2486,  1614,\n",
    "          2167,   278,  2009, 29889,    13, 29871,    13,  2277, 29937,  2799,\n",
    "          4080, 29901,    13,    13,    13,  1678,   596,  3414,   338,   304,\n",
    "         22862,  5925,  5155,  1104,  1218,   304, 16083,  5354,   773,  4874,\n",
    "         29914,  1217, 29914, 26026, 20890, 29889,   673,   408,  4874,   565,\n",
    "           278,  3030, 11286,   278,  1139,  1919,  1234,   408,   694,   565,\n",
    "           278,  3030,   947,   451,  2304,   278,  1139,  1919,  1234,   408,\n",
    "          5505,   565,   278,  3030,   338,   451,  2821,  3307,   304,  1234,\n",
    "           278,  1139, 29889,   539,    13,    13,  1678,   835,    13,   632,\n",
    "            13,  1678, 15228, 29901, 10550, 21677, 26361,   756,  1063, 11395,\n",
    "           284,   297,  3061, 19985,  1749,  8004,   310,  5164, 16021,  4235,\n",
    "         29889,   360, 12099,   526, 10712,  7945,   519,   322,  5374,   519,\n",
    "         15006, 29889,    13,    13,  1678,   894, 29901,  4683, 26361,  7945,\n",
    "           519, 29973,    13,    13,  1678,   673, 29901,  4874,    13,    13,\n",
    "          1678,   835,    13,    13,  1678, 15228, 29901, 10550, 21677, 26361,\n",
    "           756,  1063, 11395,   284,   297,  3061, 19985,  1749,  8004,   310,\n",
    "          5164, 16021,  4235, 29889,   360, 12099,   526, 10712,  7945,   519,\n",
    "           322,  5374,   519, 15006, 29889,    13,    13,  1678,   894, 29901,\n",
    "          1815, 26361,   367, 16370,   304,  6459,   322,  6655, 15724,   304,\n",
    "           278, 10122,   310,  2702,   599, 15064,   575, 29973,    13,    13,\n",
    "          1678,   673, 29901,  5505,    13,    13,  1678,   835,    13,    13,\n",
    "          1678, 15228, 29901, 10550, 21677, 26361,   756,  1063, 11395,   284,\n",
    "           297,  3061, 19985,  1749,  8004,   310,  5164, 16021,  4235, 29889,\n",
    "           360, 12099,   526, 10712,  7945,   519,   322,  5374,   519, 15006,\n",
    "         29889,    13,    13,  1678,   894, 29901,  4683,   360, 12099, 10712,\n",
    "         22909,  1765,   287,   669, 21676,  1577,    13,    13,  1678,   673,\n",
    "         29901,   694, 29871,    13,    13,  1678,   835,    13,    13,  1678,\n",
    "         15228, 29901,    13,  1678,   319,  1206,   310,   805,   979,  1014,\n",
    "         29881,  3631,   298,  4579,  4125,   313,  1799, 29928, 29950, 29897,\n",
    "          1494,  1014,   279,   496,  1217,   333,  9736,   272, 19046,   482,\n",
    "           313,  8132, 29950, 29897,  1363,   310,   263,  5796,   415,  2955,\n",
    "          7463,  1559,   327,   333,   385,  5411,   952, 29885,   338,  5439,\n",
    "         29889, 10506,   263,  1206,   756,  2360,  1063,  8967, 29889,   319,\n",
    "         29871, 29945, 29906, 29899,  6360, 29899,  1025,  6114,  1090, 29893,\n",
    "           296,   263,   274,   661, 24414, 16103,   363,   263,  5796,   415,\n",
    "          2955,  7463,  1559,   327,   333,   385,  5411,   952, 29885, 29889,\n",
    "           319, 15712,  6454,  5275, 12812, 10018,   393, 16698, 29950, 22856,\n",
    "           758, 24130, 10835,   297,   278, 13446,   285, 20634,   322,  1014,\n",
    "         29881,  3631,   298,  4579,  4125, 19540,   278,   274,   406, 12562,\n",
    "           279, 12033,   272,  1974, 29889,   512, 26614,   354,  1052, 17517,\n",
    "           310,   318,   307,  9089,   559, 29892,  6599, 17517,   310, 25995,\n",
    "           566,   309, 17546,   305,  5095,   680, 29892,   322,  9126,   274,\n",
    "           406,  6729,  1028,   979, 22576,   313,  9295, 29943, 29897,  3415,\n",
    "         22061,   362,  3025,   274,   275,  1890,   270,  6038,   482,   892,\n",
    "          8560,   408,   410, 11461,   433, 20009,  7539,  1860,   363, 19723,\n",
    "          4705, 11625, 29889,  1551,   278, 25963,  1400,  3372,  1230,  2462,\n",
    "         29892,   278, 16500, 15313,  1312,   310, 22261,  5224,  1250,   322,\n",
    "           541,   517,   384,  6788, 29889,  3561,  1212,   293, 27396,   749,\n",
    "          6382,   292, 10018,   263,  1014, 29881,  3631,   298,  4579,  4125,\n",
    "           297,   278,   301,  3774,   359,   562,  1705,  5120, 29889,  8512,\n",
    "           278,  4158,  2779,   471, 20607, 29892,   278, 16500, 10018,   694,\n",
    "           452,  2192, 19227, 25828,  4835,   916,  1135,   278,  4560, 29288,\n",
    "         29889,  2296,   471, 14914,  8976,  6703, 29889,   450,   298,  4579,\n",
    "          4125, 23556,  1490, 22020,   322,   750, 22964,  3276,  6446, 29871,\n",
    "         29896, 29945, 11405,  2678, 29889,  2439,  6788, 22020, 11684,  2618,\n",
    "         29892,   322,  1183,   471,   766, 25389,   287, 29871, 29955, 11405,\n",
    "          2678,  1728,   738,   452,  2192, 19227,   822,   293,   277, 29889,\n",
    "            13,    13,  1678,   894, 29901,    13,  1678,  1706,   979,  1014,\n",
    "         29881,  3631,   298,  4579,  4125, 29901,   263,  8617,  3100,   310,\n",
    "           263,  5796,   415,  2955,   938,   945,   661,   616,   385,  5411,\n",
    "           952, 29885, 29973,    13,    13,  1678,   673, 29901, 29871,    13,\n",
    "           268,    13,   268,    13, 29871,    13,  2277, 29937, 13291, 29901,\n",
    "            13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
    "            13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([268])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
