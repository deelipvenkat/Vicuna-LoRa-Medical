{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/minigpt_env/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import torch \n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define the size of the text blocks\n",
    "block_size = 128\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"medical_corpus.txt\",\n",
    "    block_size=block_size,\n",
    ")\n",
    "\n",
    "# DataCollator handles padding\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "torch.set_default_dtype(torch.half)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Training\n",
    "#trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling, GPT2LMHeadModel\n",
    "from transformers import TrainingArguments, Trainer, DeepSpeedPlugin, DeepSpeedConfig, Accelerator\n",
    "import torch\n",
    "import deepspeed\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define the size of the text blocks\n",
    "block_size = 128\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"medical_corpus.txt\",\n",
    "    block_size=block_size,\n",
    ")\n",
    "\n",
    "# DataCollator handles padding\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    deepspeed=\"/home/medical-llama/ds_config.json\",  # path to deepspeed configuration file\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import torch \n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define the size of the text blocks\n",
    "block_size = 128\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"medical_corpus.txt\",\n",
    "    block_size=block_size,\n",
    ")\n",
    "\n",
    "# DataCollator handles padding\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "torch.set_default_dtype(torch.half)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigpt_env/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 # Training loop</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span>model.train()                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>):  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># num of epochs</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>34 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(dataloader):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Move batch to device</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>batch = {k: v.to(device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch.items()}                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">677</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 674 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 677 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 678 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = _utils.pin_memory.pin_memory(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_device)            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 # Pad tokenized texts</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>(batch):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>padded_batch = pad_sequence([torch.tensor(text) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> text <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch], batch_first=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> padded_batch                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 # Pad tokenized texts</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>(batch):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>padded_batch = pad_sequence([torch.tensor(text) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> text <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch], batch_first=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> padded_batch                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Could not infer dtype of dict\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m34\u001b[0m                                                                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m# Training loop\u001b[0m                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m32 \u001b[0mmodel.train()                                                                               \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m33 \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m10\u001b[0m):  \u001b[2m# num of epochs\u001b[0m                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m34 \u001b[2m‚îÇ   \u001b[0m\u001b[94mfor\u001b[0m i, batch \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(dataloader):                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Move batch to device\u001b[0m                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mbatch = {k: v.to(device) \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m batch.items()}                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m37 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m633\u001b[0m in \u001b[92m__next__\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 633 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m677\u001b[0m in \u001b[92m_next_data\u001b[0m   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 674 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 677 \u001b[2m‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 678 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = _utils.pin_memory.pin_memory(data, \u001b[96mself\u001b[0m._pin_memory_device)            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92mfetch\u001b[0m       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m54 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m55 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92mpad_collate_fn\u001b[0m:\u001b[94m25\u001b[0m                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m# Pad tokenized texts\u001b[0m                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m24 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpad_collate_fn\u001b[0m(batch):                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m25 \u001b[2m‚îÇ   \u001b[0mpadded_batch = pad_sequence([torch.tensor(text) \u001b[94mfor\u001b[0m text \u001b[95min\u001b[0m batch], batch_first=\u001b[94mTrue\u001b[0m    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m padded_batch                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m27 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m28 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<listcomp>\u001b[0m:\u001b[94m25\u001b[0m                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m# Pad tokenized texts\u001b[0m                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m24 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpad_collate_fn\u001b[0m(batch):                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m25 \u001b[2m‚îÇ   \u001b[0mpadded_batch = pad_sequence([torch.tensor(text) \u001b[94mfor\u001b[0m text \u001b[95min\u001b[0m batch], batch_first=\u001b[94mTrue\u001b[0m    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m padded_batch                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m27 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m28 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCould not infer dtype of dict\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr=0.0001)\n",
    "\n",
    "# For fp16 training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Convert dataset to DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_seq_length = 10\n",
    "\n",
    "# Pad tokenized texts\n",
    "def pad_collate_fn(batch):\n",
    "    padded_batch = pad_sequence([torch.tensor(text) for text in batch], batch_first=True, padding_value=0)\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16, collate_fn=pad_collate_fn)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(10):  # num of epochs\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass under autocast\n",
    "        with autocast():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Optimizer step and update scale\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Log the loss\n",
    "        if i % 10 == 0:  # print every 100 batches\n",
    "            print(f'Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}')\n",
    "            \n",
    "    # Save the model after each epoch\n",
    "    #torch.save(model.state_dict(), f'./results/model_{epoch}.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f93709f8d90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dataloader:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(i)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">677</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 674 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 677 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 678 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = _utils.pin_memory.pin_memory(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_device)            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 # Pad tokenized texts</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>(batch):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>padded_batch = pad_sequence([torch.tensor(text) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> text <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch], batch_first=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> padded_batch                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 # Pad tokenized texts</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad_collate_fn</span>(batch):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>padded_batch = pad_sequence([torch.tensor(text) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> text <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch], batch_first=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> padded_batch                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Could not infer dtype of dict\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1 \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m dataloader:                                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[96mprint\u001b[0m(i)                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mbreak\u001b[0m                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m633\u001b[0m in \u001b[92m__next__\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 633 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m677\u001b[0m in \u001b[92m_next_data\u001b[0m   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 674 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 677 \u001b[2m‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 678 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = _utils.pin_memory.pin_memory(data, \u001b[96mself\u001b[0m._pin_memory_device)            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/home/minigpt_env/lib/python3.9/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92mfetch\u001b[0m       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m54 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m55 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92mpad_collate_fn\u001b[0m:\u001b[94m25\u001b[0m                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m# Pad tokenized texts\u001b[0m                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m24 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpad_collate_fn\u001b[0m(batch):                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m25 \u001b[2m‚îÇ   \u001b[0mpadded_batch = pad_sequence([torch.tensor(text) \u001b[94mfor\u001b[0m text \u001b[95min\u001b[0m batch], batch_first=\u001b[94mTrue\u001b[0m    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m padded_batch                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m27 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m28 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<listcomp>\u001b[0m:\u001b[94m25\u001b[0m                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m# Pad tokenized texts\u001b[0m                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m24 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpad_collate_fn\u001b[0m(batch):                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m25 \u001b[2m‚îÇ   \u001b[0mpadded_batch = pad_sequence([torch.tensor(text) \u001b[94mfor\u001b[0m text \u001b[95min\u001b[0m batch], batch_first=\u001b[94mTrue\u001b[0m    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m padded_batch                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m27 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m28 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCould not infer dtype of dict\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i)\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
