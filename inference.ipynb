{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaConfig, LlamaTokenizer,LlamaForCausalLM, LlamaTokenizer,TextDataset,DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, PeftModel, PeftConfig ,LoraConfig,TaskType\n",
    "from transformers import TrainingArguments, Trainer,GenerationConfig\n",
    "from datasets import Dataset , load_dataset\n",
    "import torch\n",
    "import accelerate\n",
    "from transformers.generation.utils import GreedySearchDecoderOnlyOutput\n",
    "import textwrap\n",
    "#import bitsandbytes\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/vicuna-weights-7B\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(path)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#okenizer.pad_token_id = tokenizer.eos_token_id\n",
    "#model = LlamaForCausalLM.from_pretrained(path,load_in_8bit=True,device_map='auto',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# \"/home/vicuna-weights-7B\" or /home/final_llama\n",
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = LlamaForCausalLM.from_pretrained(path)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=[\"#\",'##','###','</s>', \":\",'?'] \n",
    "ques='what is the capital of india ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = compute_until_stop(model, tokenizer, params, device='cuda',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = f\"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    " \n",
    "### Instruction:\n",
    "[INSTRUCTION]\n",
    " \n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(instruction):\n",
    "    return PROMPT_TEMPLATE.replace(\"[INSTRUCTION]\", instruction)\n",
    " \n",
    "#print(create_prompt(\"What is the meaning of life?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = encoding[\"input_ids\"].to('cuda')\n",
    " \n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.5,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=20,\n",
    "        min_length=1,\n",
    "        \n",
    "    )\n",
    "    with torch.inference_mode():\n",
    "        return model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=20,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "    decoded_output = tokenizer.decode(response.sequences[0])\n",
    "    response = decoded_output.split(\"### Response:\")[1].strip()\n",
    "    return \"\\n\".join(textwrap.wrap(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_vicuna(prompt, model=model):\n",
    "    prompt = create_prompt(prompt)\n",
    "    response = generate_response(prompt, model)\n",
    "    b=format_response(response)\n",
    "    a=b.split('###')\n",
    "    return a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Explain the concept of metabolic engineering and discuss a complex case where it has been successfully applied.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompting=f\"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "print(ask_vicuna(prompting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "context='The Norman dynasty had a major political, cultural and military impact on medieval Europe and even the Near East. The Normans were famed for their martial spirit and eventually for their Christian piety, becoming exponents of the Catholic orthodoxy into which they assimilated. They adopted the Gallo-Romance language of the Frankish land they settled, their dialect becoming known as Norman, Normaund or Norman French, an important literary language. The Duchy of Normandy, which they formed by treaty with the French crown, was a great fief of medieval France, and under Richard I of Normandy was forged into a cohesive and formidable principality in feudal tenure. The Normans are noted both for their culture, such as their unique Romanesque architecture and musical traditions, and for their significant military accomplishments and innovations. Norman adventurers founded the Kingdom of Sicily under Roger II after conquering southern Italy on the Saracens and Byzantines, and an expedition on behalf of their duke, William the Conqueror, led to the Norman conquest of England at the Battle of Hastings in 1066. Norman cultural and military influence spread from these new European centres to the Crusader states of the Near East, where their prince Bohemond I founded the Principality of Antioch in the Levant, to Scotland and Wales in Great Britain, to Ireland, and to the coasts of north Africa and the Canary Islands.'\n",
    "question='What type of major impact did the Norman dynasty have on modern Europe?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = f\"\"\"\n",
    "Your task is to read the following passage and answer the subsequent question based on the information provided in the passage.\n",
    "rules for answering questions:\n",
    "1. The answer must be a few words in length , single word to few words -max 20 words.\n",
    "2. follow the ordering of the passage while generating an answer.\n",
    "3. Don't add any words which are not in the passage.\n",
    "4. If a question is not answerable from the passage, write \"not answerable\" as the answer.\n",
    "\n",
    "Passage: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\n",
    "Answer: \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Military. \n"
     ]
    }
   ],
   "source": [
    "print(ask_vicuna(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
