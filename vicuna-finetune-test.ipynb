{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaConfig, LlamaTokenizer,LlamaForCausalLM, LlamaTokenizer,TextDataset,DataCollatorForLanguageModeling\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig ,LoraConfig,TaskType\n",
    "from transformers import TrainingArguments, Trainer,GenerationConfig,LineByLineTextDataset\n",
    "from datasets import Dataset , load_dataset\n",
    "import torch\n",
    "import textwrap\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import re\n",
    "from vicuna_setup import vicuna_inference\n",
    "from vicuna_pubmedqa_eval import model_pubmed_evaluator\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import Counter\n",
    "from evaluation import pub_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/vicuna-weights-7B\"\n",
    "peft_path=\"/home/medical-llama/vicuna-lora-7B\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"/home/medical-llama/vicuna-lora-7B/adapter_config.json\", 'r') as json_file:\n",
    "#    lora_config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = LlamaForCausalLM.from_pretrained(model_path)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peft_config = PeftConfig.from_pretrained(peft_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        peft_path,\n",
    "        torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=3,\n",
    "        min_length=1,\n",
    "        max_time=3,\n",
    "        max_new_tokens=3, # 3\n",
    "        forced_bos_token_id=[tokenizer.encode(\"yes\")[1], tokenizer.encode(\"no\")[1], tokenizer.encode(\"maybe\")[1]],\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/medical-llama/Pubmedqa/pubmedqa/data/pubmedqa_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_template(Question, Context):\n",
    "        \n",
    "        prompt_template=f\"\"\"\n",
    "    Respond with \"yes\",\"no\",\"maybe\" using the context & the question provided.    \n",
    "     \n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are dogs trainable?\n",
    "\n",
    "    Answer: yes\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\n",
    "\n",
    "    Answer: maybe\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are Dogs highly introverted & reserved ?\n",
    "\n",
    "    Answer: no \n",
    "\n",
    "\n",
    "    Context:\n",
    "    {Context}\n",
    "\n",
    "    Question:\n",
    "    {Question}\n",
    "\n",
    "    Answer: \n",
    "    \n",
    "    \"\"\"\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_template(Question, Context):\n",
    "        \n",
    "        prompt_template=f\"\"\"\n",
    "\n",
    "    your task is to answering research questions relating to medical domain using yes/no/maybe responses. Answer as yes if the context supports the question , answer as no if the context does not support the question , answer as maybe if the context is not clear enough to answer the question.      \n",
    "\n",
    "    ###\n",
    "            \n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are dogs trainable?\n",
    "\n",
    "    Answer: yes\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Can dogs be trained to detect and alert individuals to the presence of specific allergens?\n",
    "\n",
    "    Answer: maybe\n",
    "\n",
    "    ###\n",
    "\n",
    "    Context: Research involving dogs has been instrumental in advancing our understanding of various scientific fields. Dogs are highly trainable and sociable animals.\n",
    "\n",
    "    Question: Are Dogs highly introverted & reserved ?\n",
    "\n",
    "    Answer: no \n",
    "\n",
    "    ###\n",
    "\n",
    "    Context:\n",
    "    {Context}\n",
    "\n",
    "    Question:\n",
    "    {Question}\n",
    "\n",
    "    Answer: \n",
    "    \n",
    "    \"\"\"\n",
    "        return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_inference(pubmed_template(Question=df['Question'][5],Context=df['Context'][5]),model=model,tokenizer=tokenizer,config=pubmed_config,task='pubmedqa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pubmed_template(Question=df['Question'][0],Context=df['Context'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=GenerationConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "        beam_size=1,\n",
    "        max_length=128,\n",
    "        min_length=1,\n",
    "        max_time=10,\n",
    "        max_new_tokens=128,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vicuna_inference(\"can i take paracetamol & drink alcohol ?\",model=model,tokenizer=tokenizer,config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict={}\n",
    "for i in range(int(df.shape[0]/10)):\n",
    "    pmid=str(df['ID'][i])\n",
    "    ans=vicuna_inference(pubmed_template(Question=df['Question'][i],Context=df['Context'][i]),model=model,tokenizer=tokenizer,config=pubmed_config)\n",
    "    ans_dict[pmid]=ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict=model_pubmed_evaluator(model=model,tokenizer=tokenizer,config=pubmed_config,id_=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
